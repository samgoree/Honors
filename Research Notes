Research Notes:

I plan to take notes pretty often on what I'm doing with honors.

Sunday, 9/11/16

The second week of the semester is over now. I didn't do anything the first week, and the second week I made a schedule and started working on midi_parser.py
I'm now realizing that my dataset from UMontreal does not have note on/off for the same pitch if the voice switches. This makes sense, since it reduces the size of the midi file without impacting the sound at all, but it's bad for me because I need to split those notes up somehow. My algorithm with voice crossing and voice overlap not allowed works, though, so as soon as I solve this problem, I'll be done cleaning the data I've got.

Tuesday 9/13/16

More bug fixes to midi_parser.py. Hopefully, I can finish this up by tomorrow/thursday and start on real ML

Wednesday 9/14/16

Works! A few edits to the way I was setting upper/lower bounds made it guess correctly on examples most of the time, when it doesn't know, though, I should make it choose closest voice not lowest

Thursday 9/15/16

I messed up huge. While opening parse_midi.py, I saw there was a swap file and overwrote whatever was in the swap file without really thinking. That was an early version of the program that didn't do anything, I lost all of my work. I got some of it back using the parse_midi.py~ file that vim creates as a backup, but that was still from Tuesday. I lost a few hours of work. I'm going to try to get all of that done again today.

I managed to fix all of the lost stuff, but now I'm running into a problematic passage that no amount of algorithm can fix. I've got a crazy idea: when the rules don't specify, randomly choose a voice and continue - that way it will probably get the right answer at some point.

Friday 9/16/16

I did a bit of reorganization today and also explored additional training sets, I just want to account for everything while writing code for models. I'm currently looking at Music21, a library for music information retrival from MIT that has a bunch of bach and palestrina and other stuff that I might find useful.

Saturday 9/17/16

I started working on the generative model today, and quickly realized I was unsure what I wanted to accomplish. The easy answer is to say that I want to try a bunch of things, but I'm not sure. For now, I'm going with the idea that given the previous timestep and the current timestep in some number of voices, I want to predict the next time step of another voice.

Wednesday 9/21/16

I kept working on the generative model a bit, and read a cool article by Anna Jordanous on evaluating computational creativity research.

Thursday 9/29/16

Sorry for few notes the past few days, I didn't do much work, mostly debugging the generative model (I spent way too long on a bug that ended up being order of operations (a + b * c != (a+b) * c). I also got word back from the two people I had emailed about grad school stuff, they both basically told me to keep shopping around the way I had (and also talk to Bob Keller, which I did). I'm going to let the grad school stuff rest for a week while I get back on track with honors work.

Other than that, the GRE went well and I'm on my way. If I want to sample from a custom distribution over discrete categories, how do I do that? Never mind, it was in some old code I had written, rng.choice lets you pass in a distribution. Now I'm trying to figure out a mismatched type error

Nope, I called the wrong function.

Got the model working! It produces output! I'm going to work on a way to output midi instead of midi numbers.

And I did that, what a productive evening! I'm going home.

Friday 9/30/16

It did the thing! I have results from the simple generative model. They're not very good.

TODO:
Mini-batch training seems like a must
Validation to prevent over-fitting
Refactor to allow for modular note encodings
Product-of-experts (rhythm, pitch, contour)

Future:
Autoencoders?
Convolution across time? (a la WaveNet)

If I look at the loss function over time, it's not training really at all. I think I messed something up, but I don't know what.

Wednesday 10/5/16

Time to refactor and make sure everything is ok

minibatches - each piece needs to be the same length
my plan: randomly choose pieces, pick 8-timestep segments from each piece chosen at random

This stuff is done now, but everything's buggy.

I need to learn how convolution actually works - what would a one-dimensional convolution with kernel of size 1xk mean? Maybe I should ask Adam

Anyway, I also read the pixel-rnn article. The math is a bit confusing, but I get the gist of what they are doing.

Thursday 10/6/16

Now I'm getting to the meat of the problem: I'm not storing 2 dimensions of internal state

Should a section actually snag the timestep before as well, so it can feed that in rather than zeros? How can I do that while still allowing the start of a piece to be used?
Figured it out, doing all of that as processing outside of theano in the training loop, which is probably inefficient, but whatever.

Now I think everything's working with minibatches and validation

Nope! The network is only outputting 10 values per timestep, maybe it wants the input transposed? Nope that breaks it

Wow, it's taking the softmax across the 10 elements of the minibatch, giving a 10% chance of each note in each, which is wrong. What if I transposed before softmaxing on only multidimensional things put into the softmax function?

Thursday 10/13/16

Not much has happened this week, I made some pretty pictures, learned how to use graphviz and finished the machine learning decision tree homework
I may not get anything done today, Kuperman is out of the office tomorrow and next week is fall break, so my priority is on grad school apps and my resume.

I've modularized out note encodings from training, now I just need to figure it out for generation. I'm going to need new variables, right? Since generation is not (and shouldn't be) minibatched?

Successfully refactored, I'll build product of experts over break some time.

Monday 10/17/16

Building product of experts piece by piece, it's fall break btw and I hope to actually clock in a few hours this week.
I like referring to compile-time and run-time as a priori and a posteriori, idk if that's a real thing

Potential problem later down the line: how do I get the multiple different models to communicate while scanning? I need the outputted probabilities from all of them to make a prediction.
I'm going to have to make a scan that does all of the generative passes in parallel :(

Also TODO: move training loop from generative to a separate file and make it a more general main method, use this to test each individual part of product of experts before combining them

Friday 10/21/16

Tried to modularize the training loop, it's not going to work as well as I had thought, the simple generative and product of experts models want different information as paramters, I need to create wrapper training/validation/testing functions in their classes